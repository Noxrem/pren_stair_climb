{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREN2\n",
    "Path to recognize these little icons\n",
    "## Data Preparation for the training\n",
    "First we need to prepare image data and icons, therefore they must fit to the desired training. As Base_path we use `training` and all source files goes into `training/source` directory. F.E. the targetpictograms.\n",
    "### Download Targetpictograms\n",
    "Convert and crop them with *imagemagick*\n",
    "```console\n",
    "convert -crop 1000x1000-10-50 -gravity center +repage -density 150 Piktogramme_PREN1_HS20.pdf -quality 100 -resize 200x200 output-img.jpg\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Negative Samples\n",
    "Negative Samples sind beliebige Bilder, welche das Objekt nicht enthalten dÃ¼rfen. \n",
    "1. Download Negative Bilder https://github.com/sonots/tutorial-haartraining/tree/master/data/negatives\n",
    "1. in Arbeitsverzeichnis `training/negatives` ablegen\n",
    "1. TXT-Dokument mit Pfad zu allen negativen Bilder erstellen: `find negatives -type f > negatives.txt`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Positive Samples\n",
    "1. `cd sources`\n",
    "1. For each icon run `create_positive_variants.sh <iconname>` as parameter pass the **name** image whithout fileextension. If you have another directory structure, modify the constants in the script. probably you have to set the permissions to run it `chmod a+rx create_positive_variants.sh` It creates ten variants of each icon\n",
    "1. For each icon run `echo_create_positive_commands.sh <iconname>` with the image name as parameter and run it. check permissions either and run it. This script echoes the commands to create positive images of those variants created in previous step. copy and run each of them.\n",
    "1. add path as prefix to all lines in samplefile created by script (for each, use bbedit or textwrangler to achieve)\n",
    "1. run `create_negatives_samples.sh <iconname>` to create a set of negative images, containing other icons. adjust the array `IMG_TO_COMPOSITE` in script **before** running\n",
    "1. run script `echo_prep-training_commands.sh <iconname>` to echoes commands for further processing. you have to\n",
    "    1. collect all sample file into one\n",
    "    1. collect all negative samples include the positive samples containing other icons\n",
    "    1. create vec file\n",
    "1. Server schicken `scp -r /Users/stofers/Development/HSLU/PREN/pren_stair_climb/Raspberry_Pi/pictograms/training localadm@prenh20-sstofer.el.eee.intern:~/training`\n",
    "1. opencv_trainingcascade must be in same directory as the data! `cp ~/build/bin/opencv_traincascade training/` if not exists\n",
    "1. run training with `./opencv_traincascade -data hammer -vec hammer.vec -bg hammer_negatives.txt -numPos 13500 -numNeg 8280 -numStages 20 -w 48 -h 48 > hammer/log_hammer_training.txt`\n",
    "1. Copy cascade.xml to local directory `scp localadm@prenh20-sstofer.el.eee.intern:~/training/hammer/cascade.xml hammer/cascade.xml`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-3e6d22245d61>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mgray\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m#converting the color image to a gray scale image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mitems\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mitem_clsfr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetectMultiScale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;31m#detecting in the gray scale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m#hammers is a 2D array contaning n number of rows (n= number of hammers in the frame), 4 columns (x,y,w,h)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "classifier = \"hammer\"\n",
    "item_clsfr=cv2.CascadeClassifier(\"../\"+classifier+\"/cascade.xml\")\n",
    "#loading the cascade classifier\n",
    "\n",
    "camera=cv2.VideoCapture(0)\n",
    "#initializing the video object (0 for default webcam)\n",
    "\n",
    "while(True):\n",
    "#infinite loop to read continuous frames from the camera object\n",
    "\n",
    "    ret,img=camera.read()\n",
    "    #reading a single frame from the camera\n",
    "    gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    #converting the color image to a gray scale image\n",
    "    items=item_clsfr.detectMultiScale(gray)     \n",
    "    #detecting in the gray scale\n",
    "    #hammers is a 2D array contaning n number of rows (n= number of hammers in the frame), 4 columns (x,y,w,h)\n",
    "    for (x,y,w,h) in items:\n",
    "    #going through each and assigning the x,y,w,h\n",
    "\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "        #Drawing a rectangle bounding the faces\n",
    "        cv2.putText(img,classifier,(x,y-10),cv2.FONT_HERSHEY_SIMPLEX,0.5,(0,255,0),2)\n",
    "            \n",
    "    cv2.imshow('LIVE',img)\n",
    "    cv2.waitKey(1)\n",
    "    #showing the frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some basic stuff\n",
    "\n",
    "command create positive samples based on input images and a text-file pointing to negative images. the input image will randomly (see parameters) placed on those and position is annotated in a text file.\n",
    "```console\n",
    "/Users/stofers/openCV/opencv/cmake-build-debug/bin/opencv_createsamples -info /Users/stofers/Development/HSLU/PREN/pren_stair_climb/Raspberry_Pi/pictograms/training/hammer/hammer.txt -bg /Users/stofers/Development/HSLU/PREN/pren_stair_climb/Raspberry_Pi/pictograms/training/negatives_all.txt -img /Users/stofers/Development/HSLU/PREN/pren_stair_climb/Raspberry_Pi/pictograms/training/sources/hammer.jpg -num 1500 -w 24 -h 24 -maxxangle 0.2 -maxzangle 0.2 -maxyangle 0.2 -bgcolor 100\n",
    "```\n",
    "command *prints* filecontent and put it into a new document\n",
    "```console\n",
    "`cat FILENAME*.txt > positives.txt`\n",
    "````\n",
    "\n",
    "command list filenames ending mit .txt in the directory hammer and list them in a new file\n",
    "```console\n",
    "find hammer -name \"*.txt\" > hammer/hammer_samples.txt\n",
    "```\n",
    "\n",
    "command creates a vec-file, which is needed for cascade training.\n",
    "```console\n",
    "/Users/stofers/openCV/opencv/cmake-build-debug/bin/opencv_createsamples -info /Users/stofers/Development/HSLU/PREN/pren_stair_climb/Raspberry_Pi/pictograms/training/hammer/hammer_samples.txt -bg /Users/stofers/Development/HSLU/PREN/pren_stair_climb/Raspberry_Pi/pictograms/training/hammer_negatives.txt -vec /Users/stofers/Development/HSLU/PREN/pren_stair_climb/Raspberry_Pi/pictograms/training/hammer/hammer.vec -num 15000 -w 48 -h 48\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
