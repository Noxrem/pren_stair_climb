{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREN2\n",
    "Path to recognize these little icons\n",
    "## Data Preparation for the training\n",
    "First we need to prepare image data and icons, therefore they must fit to the desired training\n",
    "### Download Targetpictograms\n",
    "Convert and crop them with *imagemagick*\n",
    "```console\n",
    "convert -crop 1000x1000-10-50 -gravity center +repage -density 150 Piktogramme_PREN1_HS20.pdf -quality 100 -resize 200x200 output-img.jpg\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Negative Samples\n",
    "Negative Samples sind beliebige Bilder, welche das Objekt nicht enthalten d端rfen.\n",
    "1. Download Negative Bilder https://github.com/sonots/tutorial-haartraining/tree/master/data/negatives\n",
    "1. in Arbeitsverzeichnis ablegen\n",
    "1. TXT-Dokument mit Pfad zu allen negativen Bilder erstellen: `find negatives -type f > negatives.txt`\n",
    "1. Da create_samples-Tool in der Schlaufe immer die gleichen Bilder verwendete negateives negatives.txt aufsplitten: `split -l 230 negatives.txt`\n",
    "1. Filenames anpassen, f端r jedes Piktogramm ein eigenes File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Positive Samples\n",
    "1. Verzeichnisse f端r jedes Piktogramm anlegen\n",
    "1. Mit Script Command erzeugen lassen\n",
    "1. F端r jedes Piktogramm Befehl absetzen `/Users/stofers/openCV/opencv/cmake-build-debug/bin/opencv_createsamples -info /Users/stofers/Development/HSLU/PREN/pren_stair_climb/Raspberry_Pi/pictograms/training/hammer/hammer.txt -bg /Users/stofers/Development/HSLU/PREN/pren_stair_climb/Raspberry_Pi/pictograms/training/negatives_hammer.txt -img /Users/stofers/Development/HSLU/PREN/pren_stair_climb/Raspberry_Pi/pictograms/training/sources/hammer.jpg -num 1500 -w 24 -h 24 -maxxangle 0.2 -maxzangle 0.2 -maxyangle 0.2 -bgcolor 100`\n",
    "1. Vec Datei erzeugen: `/Users/stofers/openCV/opencv/cmake-build-debug/bin/opencv_createsamples -info /Users/stofers/Development/HSLU/PREN/pren_stair_climb/Raspberry_Pi/pictograms/training/hammer/hammer.txt -bg /Users/stofers/Development/HSLU/PREN/pren_stair_climb/Raspberry_Pi/pictograms/training/negatives_hammer.txt -vec /Users/stofers/Development/HSLU/PREN/pren_stair_climb/Raspberry_Pi/pictograms/training/hammer/hammer.vec -num 1500 -w 24 -h 24`\n",
    "1. Verzeichnis Training zippen\n",
    "1. Server schicken `scp /Users/stofers/Development/HSLU/PREN/pren_stair_climb/Raspberry_Pi/pictograms/training.zip localadm@prenh20-sstofer.el.eee.intern:~`\n",
    "1. Auf server entpacken `unzip training.zip`\n",
    "1. opencv_trainingcascade must be in same directory as the data!\n",
    "1. run training with `./opencv_traincascade -data hammer -vec hammer/hammer.vec -bg negatives_hammer.txt -numPos 1500 -numNeg 1500 -numStages 15 -w 24 -h 24`\n",
    "1. Copy cascade.xml to local directory `scp localadm@prenh20-sstofer.el.eee.intern:~/training/hammer/cascade.xml hammer/cascade.xml`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "classifier = \"hammer\"\n",
    "item_clsfr=cv2.CascadeClassifier(\"../\"+classifier+\"/cascade.xml\")\n",
    "#loading the cascade classifier\n",
    "\n",
    "camera=cv2.VideoCapture(0)\n",
    "#initializing the video object (0 for default webcam)\n",
    "\n",
    "while(True):\n",
    "#infinite loop to read continuous frames from the camera object\n",
    "\n",
    "    ret,img=camera.read()\n",
    "    #reading a single frame from the camera\n",
    "    gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    #converting the color image to a gray scale image\n",
    "    items=item_clsfr.detectMultiScale(gray)     \n",
    "    #detecting in the gray scale\n",
    "    #hammers is a 2D array contaning n number of rows (n= number of hammers in the frame), 4 columns (x,y,w,h)\n",
    "    for (x,y,w,h) in items:\n",
    "    #going through each and assigning the x,y,w,h\n",
    "\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "        #Drawing a rectangle bounding the faces\n",
    "        cv2.putText(img,classifier,(x,y-10),cv2.FONT_HERSHEY_SIMPLEX,0.5,(0,255,0),2)\n",
    "            \n",
    "    cv2.imshow('LIVE',img)\n",
    "    cv2.waitKey(1)\n",
    "    #showing the frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
