{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREN2\n",
    "Path to recognize these little icons\n",
    "## Data Preparation for the training\n",
    "First we need to prepare image data and icons, therefore they must fit to the desired training. As Base_path we use `training` and all source files goes into `training/source` directory. F.E. the targetpictograms.\n",
    "### Download Targetpictograms\n",
    "Convert and crop them with *imagemagick*\n",
    "```console\n",
    "convert -crop 1000x1000-10-50 -gravity center +repage -density 150 Piktogramme_PREN1_HS20.pdf -quality 100 -resize 200x200 output-img.jpg\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Negative Samples\n",
    "Negative Samples sind beliebige Bilder, welche das Objekt nicht enthalten dÃ¼rfen. \n",
    "1. Download Negative Bilder https://github.com/sonots/tutorial-haartraining/tree/master/data/negatives\n",
    "1. in Arbeitsverzeichnis `training/negatives` ablegen\n",
    "1. TXT-Dokument mit Pfad zu allen negativen Bilder erstellen: `find negatives -type f > negatives.txt`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Positive Samples\n",
    "1. `cd sources`\n",
    "1. For each icon run `create_positive_variants.sh <iconname>` as parameter pass the **name** image whithout fileextension. If you have another directory structure, modify the constants in the script. probably you have to set the permissions to run it `chmod a+rx create_positive_variants.sh` It creates ten variants of each icon\n",
    "1. run `create_negatives_samples.sh <iconname>` to create a set of negative images, containing other icons.  \n",
    "<!-- 1. For each icon run `echo_create_positive_commands.sh <iconname>` with the image name as parameter and run it. check permissions either and run it. This script echoes the commands to create positive images of those variants created in previous step. copy and run each of them. \n",
    "1. add path as prefix to all lines in samplefile created by script (for each, use bbedit or textwrangler to achieve) -->\n",
    "1. run script `echo_prep-training_commands.sh <iconname>` to echoes commands for further processing. you have to\n",
    "    1. move to base dir\n",
    "    1. Collect negative sample data\n",
    "    1. Create positive samples on top of negatives\n",
    "    1. ajust image path in annotation file\n",
    "    1. Collect all sample-files\n",
    "    1. create vec file\n",
    "    1. run training\n",
    "    \n",
    "<!--\n",
    "1. Server schicken `scp -r /Users/stofers/Development/HSLU/PREN/pren_stair_climb/Raspberry_Pi/pictograms/training localadm@prenh20-sstofer.el.eee.intern:~/training`\n",
    "1. opencv_trainingcascade must be in same directory as the data! `cp ~/build/bin/opencv_traincascade training/` if not exists\n",
    "1. run training with `nohup ./opencv_traincascade -data hammer -vec hammer.vec -bg hammer_negatives.txt -numPos 3375 -numNeg 3375 -numStages 10 -w 48 -h 48  -precalcValBufSize 2048 precalcIdxBufSize 2048 -mode ALL -numThreads 8 > hammer/log_hammer_training.txt`\n",
    "1. Copy cascade.xml to local directory `scp localadm@prenh20-sstofer.el.eee.intern:~/training/hammer/cascade.xml hammer/cascade.xml`\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "hammer = \"hammer\"\n",
    "ruler = \"ruler\"\n",
    "paintbucket = \"paintbucket\"\n",
    "pencil = \"pencil\"\n",
    "wrap = \"wrap\"\n",
    "wrench = \"wrench\"\n",
    "hammer_clsfr=cv2.CascadeClassifier(\"../\"+hammer+\"/cascade.xml\")\n",
    "ruler_clsfr=cv2.CascadeClassifier(\"../\"+ruler+\"/cascade.xml\")\n",
    "paintbucket_clsfr=cv2.CascadeClassifier(\"../\"+paintbucket+\"/cascade.xml\")\n",
    "pencil_clsfr=cv2.CascadeClassifier(\"../\"+pencil+\"/cascade.xml\")\n",
    "wrap_clsfr=cv2.CascadeClassifier(\"../\"+wrap+\"/cascade.xml\")\n",
    "wrench_clsfr=cv2.CascadeClassifier(\"../\"+wrench+\"/cascade.xml\")\n",
    "#loading the cascade classifier\n",
    "\n",
    "camera=cv2.VideoCapture(0)\n",
    "#initializing the video object (0 for default webcam)\n",
    "\n",
    "while(True):\n",
    "#infinite loop to read continuous frames from the camera object\n",
    "\n",
    "    ret,img=camera.read()\n",
    "    #reading a single frame from the camera\n",
    "    gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    #converting the color image to a gray scale image\n",
    "    hammers=hammer_clsfr.detectMultiScale(gray)  \n",
    "    rulers=ruler_clsfr.detectMultiScale(gray)\n",
    "    paintbuckets=paintbucket_clsfr.detectMultiScale(gray)\n",
    "    pencils=pencil_clsfr.detectMultiScale(gray)\n",
    "    wraps=wrap_clsfr.detectMultiScale(gray)\n",
    "    wrenchs=wrench_clsfr.detectMultiScale(gray)\n",
    "    #detecting in the gray scale\n",
    "    #hammers is a 2D array contaning n number of rows (n= number of hammers in the frame), 4 columns (x,y,w,h)\n",
    "    for (x,y,w,h) in hammers:\n",
    "    #going through each and assigning the x,y,w,h\n",
    "\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "        #Drawing a rectangle bounding the faces\n",
    "        cv2.putText(img,hammer,(x,y-10),cv2.FONT_HERSHEY_SIMPLEX,0.5,(0,255,0),2)\n",
    "        \n",
    "    for (x,y,w,h) in rulers:\n",
    "    #going through each and assigning the x,y,w,h\n",
    "\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "        #Drawing a rectangle bounding the faces\n",
    "        cv2.putText(img,ruler,(x,y-10),cv2.FONT_HERSHEY_SIMPLEX,0.5,(0,255,0),2)\n",
    "            \n",
    "    for (x,y,w,h) in paintbuckets:\n",
    "    #going through each and assigning the x,y,w,h\n",
    "\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "        #Drawing a rectangle bounding the faces\n",
    "        cv2.putText(img,paintbucket,(x,y-10),cv2.FONT_HERSHEY_SIMPLEX,0.5,(0,255,0),2)\n",
    "    for (x,y,w,h) in pencils:\n",
    "    #going through each and assigning the x,y,w,h\n",
    "\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "        #Drawing a rectangle bounding the faces\n",
    "        cv2.putText(img,pencil,(x,y-10),cv2.FONT_HERSHEY_SIMPLEX,0.5,(0,255,0),2)\n",
    "    for (x,y,w,h) in wraps:\n",
    "    #going through each and assigning the x,y,w,h\n",
    "\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "        #Drawing a rectangle bounding the faces\n",
    "        cv2.putText(img,wrap,(x,y-10),cv2.FONT_HERSHEY_SIMPLEX,0.5,(0,255,0),2)\n",
    "    for (x,y,w,h) in wrenchs:\n",
    "    #going through each and assigning the x,y,w,h\n",
    "\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "        #Drawing a rectangle bounding the faces\n",
    "        cv2.putText(img,wrench,(x,y-10),cv2.FONT_HERSHEY_SIMPLEX,0.5,(0,255,0),2)\n",
    "            \n",
    "    cv2.imshow('LIVE',img)\n",
    "    cv2.waitKey(1)\n",
    "    #showing the frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some basic stuff\n",
    "\n",
    "command create positive samples based on input images and a text-file pointing to negative images. the input image will randomly (see parameters) placed on those and position is annotated in a text file.\n",
    "```console\n",
    "/Users/stofers/openCV/opencv/cmake-build-debug/bin/opencv_createsamples -info /Users/stofers/Development/HSLU/PREN/pren_stair_climb/Raspberry_Pi/pictograms/training/hammer/hammer.txt -bg /Users/stofers/Development/HSLU/PREN/pren_stair_climb/Raspberry_Pi/pictograms/training/negatives_all.txt -img /Users/stofers/Development/HSLU/PREN/pren_stair_climb/Raspberry_Pi/pictograms/training/sources/hammer.jpg -num 1500 -w 24 -h 24 -maxxangle 0.2 -maxzangle 0.2 -maxyangle 0.2 -bgcolor 100\n",
    "```\n",
    "command *prints* filecontent and put it into a new document\n",
    "```console\n",
    "`cat FILENAME*.txt > positives.txt`\n",
    "````\n",
    "\n",
    "command list filenames ending mit .txt in the directory hammer and list them in a new file\n",
    "```console\n",
    "find hammer -name \"*.txt\" > hammer/hammer_samples.txt\n",
    "```\n",
    "\n",
    "command creates a vec-file, which is needed for cascade training.\n",
    "```console\n",
    "/Users/stofers/openCV/opencv/cmake-build-debug/bin/opencv_createsamples -info /Users/stofers/Development/HSLU/PREN/pren_stair_climb/Raspberry_Pi/pictograms/training/hammer/hammer_samples.txt -bg /Users/stofers/Development/HSLU/PREN/pren_stair_climb/Raspberry_Pi/pictograms/training/hammer_negatives.txt -vec /Users/stofers/Development/HSLU/PREN/pren_stair_climb/Raspberry_Pi/pictograms/training/hammer/hammer.vec -num 15000 -w 48 -h 48\n",
    "```\n",
    "\n",
    "last one\n",
    "```console\n",
    "nohup /Users/stofers/openCV/opencv/cmake-build-debug/bin/opencv_traincascade -data hammer -vec hammer.vec -bg hammer_negatives.txt -numPos 1350 -numNeg 900 -numStages 7 -w 48 -h 48  -precalcValBufSize 2048 precalcIdxBufSize 2048 -mode ALL -numThreads 8 -minHitRate 0.999 -maxFalseAlarmRate 0.2 > hammer/log_hammer_training.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
